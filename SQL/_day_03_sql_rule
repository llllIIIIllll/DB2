***************************************************************************************************
***************************************************************************************************
***************************************************************************************************
+SQL编写规范基本要求
|-------+ Teradata关键字和保留字大写
|-------+ SELECT FROM WHERE AND OR UNION INSERT DELETE GROUP HAVING COUNT...
|-------+ 代码行中关键字不允许使用简写方式 (SEL DEL)
|-------+ 表名 视图名 宏 存储过程名 字段名 字段别名 以首字母大写加下划线连接符命名 (Acct_Id Type_Id)
|-------+ 四个空格为一个缩进量 所有缩进皆为一个缩进量的整数倍
|-------+ 对应的括号通常要求在同一列的位置
|-------+ 每行宽度不超过120字符(每个字符为8个点阵宽)
|-------+ 超过行宽的代码可拆行或上行左对齐编排
|-------+ 同一级别的字句间对齐
|-------+ 分号 放SQL语句最后 单独占一行
***************************************************************************************************
|---1---| 字段排列要求
|-------+ SELECT语句选择的字段按每行一个字段的方式编排
|-------+ SELECT单字后面一个缩进量后直接跟首个选择的字段，即字段离首起两个缩进量
|-------+ 其它字段前导两个缩进量再跟一‘，’点后放置字段名
===================================================================================================
SELECT    First_Name
          ,Last_Name
          ,Employee_Number    AS Employee_ID
          ,Salary_Amount      AS Employee_Salary
FROM      Employee
WHERE     Salary_Amount > 35000,00
===================================================================================================
|---2---| 字段分隔符’,’书写位置要求
|-------+ 两个字段之间的’,’分隔符紧跟在第二个字段的前面
|---3---| 字段别名‘AS’语句编写要求
|-------+ AS’语句应与相应的字段在同一行
|-------+ 多个字段的‘AS’建议尽量对齐在同一列上
|-------+ 字段别名在同一个查询例程中可以被引用
===================================================================================================
SELECT    sale.Sec_Code        AS Sec_Code
          ,SUM(sale.Trade_Vol * (cst.Calcu_Quotiety + cst.Calcu_Quotiety2 / 100))
                               AS Trade_Sale_Vol
          ,SUM(sale.Trade_Vol * cst.Calcu_Quotiety2 + sale.Trade_Vol * sale.Trade_pPrice*cst.Calcu_Quotiety)
                               As Trade_Sale_Amt
          ,ZEROIFNULL(Trader_Sale_Amt / NULLIFZERO(Trade_Sale_Vol))
                               As Trade_Sale_Price
===================================================================================================
|---4---| SELECT字句排列要求
|-------+ 换行编写
|-------+ 与相应的SELECT语句对齐
|-------+ 子句后续的代码离子句首字母两个缩进量起编写
|-------+ WHERE子句下的逻辑判断符AND、OR等与WHERE右对齐编排
|-------+ 超过两个缩进量长度的子句加一空格后编写后续代码，如ORDER BY GROUP BY等
===================================================================================================
SELECT    First_Name
          ,Last_Name
          ,Employee_Number    AS Employee_ID
          ,Salary_Amount      AS Employee_Salary
FROM      Employee
WHERE     Salary_Amount > 35000.00
  AND     Salary_Amount < 85000.00
   OR     department_Number = 403
ORDER BY  First_Name
;          
===================================================================================================
|---5---| 运算符前后间隔要求
|-------+ 算术运算符、逻辑运算符的前后至少要保留一个空格
===================================================================================================
SELECT    First_Name
          ,Last_Name
          ,Employee_Number    AS Employee_ID
          ,Salary_Amount      AS Employee_Salary
          ,(Salary_Amount + Salary_Amount * 2) / 1.5
                              AS Employee_Salary_Double          
FROM      Employee
WHERE     Salary_Amount > 35000.00
  AND     Salary_Amount < 85000.00
   OR     department_Number = 403
ORDER BY  First_Name
;   
===================================================================================================
|---6---| CASE语句编写要求
|-------+ CASE语句从CASE开头到END结束要用括弧包括起来，并给结果值赋别名字段
|-------+ WHEN子句在CASE语句的下一行并缩进两个缩进量后编写
|-------+ 每个WHEN子句都在同一行编写，如果语句较长可换行编写
|-------+ CASE语句必须包含ELSE子语
===================================================================================================
SELECT    First_Name
          ,Last_Name
          ,Employee_Number    AS Employee_ID
          ,Salary_Amount      AS Employee_Salary
          ,(CASE
                  WHERE Salary_Amount < 5000 THEN Salary_Amount * 2
                  WHERE Salary_Amount < 6000 THEN Salary_Amount * 1.5
                  ELSE  (Salary_Amount + Salary_Amount * 2) / 2.5
          END
          )                   AS Employee_Salary_Double
FROM      Employee
WHERE     Salary_Amount > 35000.00
  AND     Salary_Amount < 85000.00
   OR     department_Number = 403
ORDER BY  First_Name
;          
===================================================================================================
|---7---| CASE语句编写要求
|-------+ 子查询必须用括号括起来
|-------+ 子查询可以是IN或NOT IN子句的操作目标
|-------+ 子查询可以是EXISTS或NOT EXISTS子句的操作目标
|-------+ 子查询支持限定词ALL,ANY,SOME
|-------+ 子查询支持LIKE或NOT LIKE
|-------+ 子查询中可以指定匹配多个字段
|-------+ 子查询结果均为唯一值，即自动去除重复记录，相当于自动加上 DISTINCT 关键词
|-------+ ORDER BY不能用于子查询内
|-------+ 子查询中最多可以指定64个表或试图
===================================================================================================
SELECT    ......
FROM      vt_Txn_Trade_His_Date        a1
LEFT JOIN
          (SELECT b1.Trade_Seat_Code
                  ,b2.Acct_ID
           FROM   vt_Txn_Trade_His_Date_B        b1,
                  (SELECT    Acct_ID
                             ,MIN(Trade_NO)      AS Trade_NO
                   FROM      vt_Txn_Trade_His_Date_B
                   WHERE     TRIM(Acct_ID) <> ''
                   GROUP BY  Acct_ID
                   HAVING    COUNT(Acct_ID) >= 2
                  )          b2
           WHERE b1.Trade_NO = b2.Trade_NO       
          )       a2
ON        a1.Acct_ID = a2.Acct_ID
;
===================================================================================================
|---8---| 表别名定义的约定
 表别名采用简单字符命名
|-------+ 多层次的嵌套子查询别名之前要体现层次关系
|-------+ SQL语句别名的命名，分层命名，从第一层次至第四层次，分  别用P、S、U、D（都是大写字母）表示，
        |-------+ 取意为Part,Segment,Unit,Detail。也可用a、b、c、d来表示第一层次到第四层次 
|-------+ 对于同一层次的多个字句，在字母后加1、2、3、4……区分
|-------+ 有需要的情况下对表别名进行注释 
===================================================================================================
|---9---| 变量引用
|-------+ 在SQL语句中引用变量时，要在变量名两端加花括号 ，
|-------+ 对日期变量的引用要在单引号内，如‘${MYDATE}’
===================================================================================================
===================================================================================================
--LEFT JOIN
SELECT    seat.DMN_Date
          ,seat.Sec_Code
          ,COALESCE (path.Branch_Code, '')
FROM      (SELECT    *
           FROM      ${SUMDB}.JCB_Txn_Sec_Seat
           WHERE     Dmn_Date = '${DayOfData}'
          )    seat
LEFT JOIN
          (SELECT DISTINCT
                  Branch_Code
                  ,seat_Code
           FROM   ${PD_VIEW_AP}.DMN_V_Trade_Path_His
           WHERE  Eff_Date <= '{$DayOfData}'
           AND    '${DayOfData}' < End_Date
          )    path
ON        seat.seat_Code = path.seat_Code
;
===================================================================================================
--FULL OUT JOIN
SELECT    COALESCE    (seat.DMN_Date    ,    '30001231')
          ,COALESCE   (seat.Sec_Code    ,    '')
          ,COALESCE   (path.Branch_Code ,    '')
FROM      (SELECT    *
          FROM       ${SUMDB}.JCB_Txn_Sec_Seat
          WHERE      Dmn_Date = '${DayOfData}'
          )    seat
FULL OUT JOIN
         (SELECT DISTINCT
                 Branch_Code
                 ,seat_Code
         FROM    ${PD_VIEW_AP}.DMN_V_Trade_Path_His
         WHERE   Eff_date <= '${DayOfData}'
         AND     '${DayOfData}' <= End_data
         )    path
ON       seat.seat.Code = path.seat_code
;
===================================================================================================
+NULL值处理约定
|-------+ 数字型字段NULL值的处理  ZEROIFNULL（数字型字段）或COALESCE（数字型字段，0）
|-------+ 字符型字段NULL值的处理  COALESCE（数字型字段，’’）
|-------+ 提取日期型字段的处理    CAST   (日期型字段 AS DATE FORMAT  ‘YYYYMMDD’)
===================================================================================================
+除法运算被0除的处理
|-------+ NULLIFZERO  
===================================================================================================
+比较逻辑运算处理约定
|-------+ 字符型比较的处理
CASE
WHEN  (SUBSTR (Brandk＿ID  , 1 , 2 ) ( CASESPECIFIC ) ) = ‘Gg’  THEN  ‘1’
CASE
WHEN  (SUBSTR (STOCK＿ID  , 8 , 2 ) ( NOT  CASESPECIFIC ) ) = ‘SS’  THEN  ‘1’
===================================================================================================
+日期型比较的处理
CAST (TRADE ＿DATE  AS  DATE  FORMAT  'YYYYMMDD') = 
CAST ('$DayOfData'  AS  DATE  FORMAT  'YYYYMMDD')
===================================================================================================
+注释约定
|-------+ 编写人/编写日期
|-------+ 修改人/修改日期
|-------+ 该脚本的编写目的与主要内容
|-------+ 如果有特殊处理、特别的技巧等内容，一定要在注释中详细说明
|-------+ 每一大的模块之前要有注释，说明该模块的主要作用，多行注释可用 '/*     */' 来标识，单行注释可用--来标识
|-------+ 对于较为复杂的过程必须注明代码实现的功能以及相关的创建、修改记录 
===================================================================================================
/*
实现功能：获取会员、管理基金公司基本信息
源    表：PAR＿MEMBER ＿HIS、SEC Fund ＿Mgmt ＿Com ＿his(建议)
目标  表：JCB ＿TRADE ＿MEMBER(建议)
修改记录：Created by Linxt at 20031203
*/
DELETE    FROM ${SUBDB}.JCB __TRADE __MEMBER
WHERE     Trade __Data = '${DayOfData}'
;
INSERT INTO ${SUMDB}.JCB __TRADE __MEMBER 
            (Trade __Date
            ,MEN __CODE
            ...
            )
SELECT    DISTINCT              ----Member   info
            '${DayOfData}'
            ,Mem ＿Code
            ,......
FROM   ${JCBDB}.PAR ＿MEMBER ＿HIS
WHERE  Eff ＿Date <= '${DayOfData}'
AND    End＿Date >= '${DayOfData}'
UNION  ALL                                  ----Fund  Management  Company  info
SELECT    DISTINCT
            '${DayOfData}'
            ,Fund ＿Management ＿Company ＿Code
            ,......
FROM        ${JCBDB}.SEC ＿Fund ＿Mgmt ＿Com ＿his
WHERE       Eff ＿Date <= '${DayOfData}'
AND         End＿Date >= '${DayOfData}'
;
===================================================================================================
***************************************************************************************************
***************************************************************************************************
***************************************************************************************************
+SQL的优化
|-------+ 系统负载过大，登陆查询的用户过多
|-------+ 相关表被锁
        |-------+ Database lock Table lock
        |-------+ Utility lock 如Arcmain Tpump
|-------+ 数据库内部操作
        |-------+ Crashdumps
        |-------+ Mini-Cylpacks/Packdisk
|-------+ 查询运行太偏或IO过大
        |-------+ SQL编写不规范
        |-------+ Primary Index选择不当
        |-------+ 错误的执行路径
|-------+ 在Teradata数据库中，所有物理表的记录都是依据其PI值作哈希分布，均匀的分布在各个AMP上。
|-------+ 在多表进行join的时候，不同物理表的记录必须转移到相同的AMP上进行关联比较。当然，发生转移的记录只是物理表的拷贝，占用的是SPOOL空间，原表数据不会发生任何变动。
|-------+ 表Join之前的数据转移方式只有三种：
        |-------+ 无需转移(Built locally)
        |-------+ 两张表按关联字段进行记录重新分布(ALL-AMPs Redistributed)
        |-------+ 大表不动，小表在所有AMP上进行复制(ALL-AMPs Duplicated)
|-------+ 如果两张表的关联字段正好是各自的PI时，那么不需要任何额外转移的工作，各AMP上的数据可以直接进行比较，这是性能最好的情况之一。
===================================================================================================
JOIN
Merge Join		Rowhash  match                                                                 
            	在关联之前，两表都必须按关联字段的rowhash值进行排序
							记录所在的block只需访问一次
							关联条件为等值条件
Product Join	Row  match
							在关联之前，两表都不需要排序
							记录所在的block可能被访问多次
Hash  Join		Rowhash  match（利用二分法）
							在关联之前，将小表读入缓存中并按关联字段的rowhash值进行排序，但大表不需排序
Nest  Join		UPI  match
							发生关联的A、B表必须满足特殊的条件：
							1 必定通过UPI、NUPI或USI三种方式之一访问A表；
							2 B表的关联字段必定是其UPI、NUPI或USI
Exclusion 
Merge  
Join					Rowhash  exclusion(any true any unknown all false)
							其他同Merge  Join
===================================================================================================
--Merge Join	(Rows must be on the same AMP to be joined.)  
|------+ 两个表的数据量都比较大时
|------+ 用来Join的记录必须位于相同的AMP上
|------+ 仅仅读取每个表一次.
|------+ 对于等值条件的Join，优化器经常会选用Merge Join.
|------+ 通常情况下比product join的效率更高.
--流程
|------+ 找到一个小表.
|------+ 如果需要:
|------+ 将一个或者两个表要用到的数据都放在Spool空间里.
|------+ 基于Join列的hash值将记录重分布到相应的AMP.
|------+ 根据Join列的hash顺序对spool里面的记录进行排序.
===================================================================================================
--Product Join (Rows must be on the same AMP to be joined.)
|------+ 不对记录做排序
|------+ 如果内存里面放不下的时候需要多次读取某张表.
|------+ Table1 的每条记录要与 Table2 的每条记录进行比对.
|------+ 满足条件的记录会被放到 spool空间中.
|------+ 之所以会被称作Product Join 是因为: 总共的比较次数 = Table 1 的记录条数 * Table 2的记录条数
|------+ 当内存里面不能存放某一个表的所有数据的时候，这种比较会变得非常的消耗资源，因为总是需要内外存的交换。
|------+ 如果没有where条件，Product Join通常会产生无意义的结果.
--流程
|------+ 找到小表并在Spool空间中复制到所有AMP上.
|------+ 在每个AMP上，Spool空间里的小表的每一行和大表在该AMP上的每一行做Join.
===================================================================================================
--Hash Join
|------+ 优化器技术有效的将小表放在Cache内存中，并且与未排序的大表进行关联.
|------+ 这种join将减少大表的排序、重分布或者拷贝.
--流程
|------+ 找到小表.
|------+ 重分布小表或者复制小表到各个AMP的内存中.
|------+ 将小表在Cache内存中按照join字段的 row hash顺序排序.
|------+ 将记录放在内存中.
|------+ 用大表的join字段的row hash在内存中进行折半查找.
===================================================================================================
***************************************************************************************************
***************************************************************************************************
***************************************************************************************************
===================================================================================================
/*  ETL SQL 优化 */
--选取目标------------->收集信息------------->Explain分析
     ^                                            |
     |                                            |
     |                                            V
--记录归档<-------------运行跟踪<-------------过程优化
===================================================================================================
1选取目标
--  参照ETL_JOB_LOG表
--	该表为ETL Automation的日志表
--	该表记录了一个月内所有作业的执行情况
--	该表记录了每日每个作业的起始时间和结束时间
--	特别关注耗时TOP 1
---------------------------------------------------------------------------------------------------
SELECT
    txdate
    ,etl_system 
    ,etl_job
    ,MIN(starttime) (TIMESTAMP(0)) AS start_time
    ,MAX(endtime)   (TIMESTAMP(0)) AS end_time
    ,(end_time - start_time) HOUR TO SECOND(0) AS duration
FROM
(
SELECT
    txdate
    ,etl_system 
    ,etl_job
    ,starttime
    ,endtime
FROM   etlauto.etl_job_log
WHERE  etl_system <> 'FTP'
AND returncode = '0'
AND txdate BETWEEN DATE - 1 AND DATE - 1
qualify rank() over(partition BY txdate,etl_system,etl_job ORDER BY jobsessionid DESC) = 1
)  a1
GROUP BY 1, 2, 3
ORDER BY 6 DESC
===================================================================================================
2收集信息
--	调优之前必须收集的三类信息：
--	目标SQL
--	相关表的定义（特别关注PI或PPI定义）
--	相关表的大小
--	表定义可以通过Show Query命令展现，可以一次解析出所有的视图、物理表；
--	表大小可以通过以下SQL获取：
---------------------------------------------------------------------------------------------------
SELECT DatabaseName
			 ,TableName
			 ,SUM(CurrentPerm)/1024/1024 											AS CurrentPerm
			 ,(100 - (AVG(CurrentPerm)/MAX(CurrentPerm)*100)) AS SkewFactor 
FROM Dbc.TableSize 
WHERE DatabaseName IN ('bssdata','zjbic')
AND TableName IN (
			 'OFR_MAIN_ASSET_HIST_A'
			 ,'BIC_NET_CDR_MON_CALL_OFR_A'
)
GROUP BY 1,2
===================================================================================================
3Explain分析
--	执行命令Explain Query，观察当前优化器所选择的执行路径
--	什么是合理的执行路径？
--	大表不会发生all-AMPs Duplicated
--	大表应尽量避免all-AMPs Redistributed，尽可能直接引用或Built locally
--	小表应尽量all-AMPs Duplicated 或 all-AMPs Redistributed
--	在多表进行关联的时候，最佳的情况是第一次关联就使Spool结果集缩至最小，应避免大表与大表先发生关联
--	若关联的一方记录集极小（<100条），尽可能采取product join
--	分区表首先进行分区筛选，尽可能避免all-Partitions retrieve
--	不良的执行路径意味着长耗时和资源浪费，需要进行优化
---------------------------------------------------------------------------------------------------
===================================================================================================
4优化手段
+PDM设计
|-----+调整PI
      |-----+ 关联使用频率越高越好
      |-----+ 物理表偏移因子越小越好（大表控制在30%以内）
      |-----+ PI字段的更新频率越低越好
|-----+使用PPI
      |-----+ 分区筛选条件只能是”分区字段(>,=,<)常量“，其中常量不能使用系统参数，例如CURRENT_DATE、DATE、 CURRENT_TIME、TIME
      |-----+ 使用RANG_N方式，不建议使用CASE_N方式
      |-----+ PPI负作用
            |-----+ 全表扫描速度下降（例如：对全表做聚合操作）
            |-----+ 与NPPI表的关联速度下降
            |-----+ 优化器认为PPI大表经过分区筛选后变成小表，导致执行路径变差
|-----+其他设计(multiset,no fallback)
      |-----+ 建议对小表的索引字段以及在表关联时多次出现的条件字段定期收集统计信息
      |-----+ 对大表可以采用using sample方式节省收集统计的时间
							COLLECT stat USING sample ON bssdata.EVT_ORDER_HIST_A COLUMN(Sales_Telecom_Area_ID);
      |-----+ 分区表之间进行关联，建议对partition做统计
 							COLLECT stat ON bssdata.FIN_CACCT_BSI_HIST_G COLUMN(PARTITION);
      |-----+ 统计信息不宜过少，太少难以引导优化器；也不宜过多，过多可能误导优化器
+SQL技术调整：
|-----+增加统计信息，改善执行路径
      |-----+ 当SQL运行时间过长时（例如超过1小时），极有可能是执行路径异常。如果该SQL仍在运行中
            |-----+ 1 大表做ALL-AMPs Duplicated  
            |-----+ 2 大表做ALL-AMPs Redistributed，但CPU skew达到95%以上 
            |-----+ 3 大表与大表做 product join
      |-----+ 如果该SQL不在运行中，使用explain命令进行诊断，仍然是关注上述三个重点
|-----+减少不必要的数据排重
      |-----+ 按照业务逻辑判断没有重复数据（例如取当前记录），应该杜绝进行排重操作
      |-----+ 因数据质量问题导致的排重，应该从源头上进行清理
|-----+如果无法避免排重，改用分步方式
      |-----+ 重复记录占比大于30%，不建议直接使用QUALIFY  ROW_NUMBER排重，而是按照分步方式排重
      |-----+ 重复记录占比小于30%，直接使用QUALIFY  ROW_NUMBER()排重。
|-----+复用和减少临时表
      |-----+ 每做一次数据处理（关联、聚合、过滤）就生成一张可变临时表；
      |-----+ 可变临时表一般只使用一次；
      |-----+ 临时表过多，会有以下影响
                  |-----+ 脚本逻辑不清晰，层次复杂
                  |-----+ 日志反映信息较少，脚本调试麻烦
                  |-----+ 可变临时表无法收集统计信息
                  |-----+ 强制指定执行路径，性能可能更差
      |-----+ 建议如下：
                  |-----+ 减少临时表使用，只对复用的中间表建立临时表；
                  |-----+ 对于多表关联出现的路径较差问题，尽量通过收集统计信息来解决。
|-----+大表预处理缩小结果集
      |-----+ 有些SQL先与大表全表数据作关联，然后只使用了其中部分关联结果。因此，可以对大表作预处理，只取最后用到的数据再进行关联
|-----+代码共用
      |-----+ 在做多步并插的时候，如果各步关联的表完全一致，可以考虑将多步合并为一
      |-----+ 在做多步并插的时候，如果各步关联的大表一致，可考虑建立临时表
      |-----+ 如果多个作业存在相同的大查询，可以考虑将该查询作为单独的作业
|-----+竖表变横表使用聚合方式替代自关联方式
+SQL逻辑调整：
|-----+减少大表访问，直接引用其他作业结果
|-----+简化业务规则，避免和大表关联
|-----+资源合理分配
|-----+混合负载管理
|-----+流程优化
|-----+延迟无应用脚本运行时间
---------------------------------------------------------------------------------------------------
===================================================================================================
